{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from FasterRCNN import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  Build faster rcnn model\n",
    "img_input, shared_layers, roi_input = build_base_model()\n",
    "rpn_class, rpn_position = build_rpn_layer(shared_layers)\n",
    "rpn_class_model = Model(img_input, rpn_class)\n",
    "rpn_positoin_model = Model(img_input, rpn_position)\n",
    "vgg_model = Model(img_input, shared_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compile the models\n",
    "model_rpn, model_classifier, model_all = faster_rcnn(shared_layers, roi_input, img_input)\n",
    "model_rpn.compile(optimizer='adam', loss=[rpn_loss_cls(9), rpn_loss_regr(9)])\n",
    "model_classifier.compile(optimizer='adam',\n",
    "                         loss=[class_loss_cls, class_loss_regr(37)],\n",
    "                         metrics={'dense_class_{}'.format(38): 'accuracy'})\n",
    "model_all.compile(optimizer='sgd', loss='mae')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hyperparameters and settings\n",
    "epoch_length = 1\n",
    "num_epochs = 200\n",
    "iter_num = 0\n",
    "losses = np.zeros((epoch_length, 5))\n",
    "num_rois = 4\n",
    "best_loss = float('inf')\n",
    "output_model_name = \"weight/trash_model\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "input_img_data = np.load('bacup/test_input.npy', allow_pickle=True)\n",
    "label_data = np.load('bacup/test_output.npy', allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "for epoch_num in range(num_epochs):\n",
    "    rpn_accuracy_for_epoch = []\n",
    "    for img, annotation in zip(input_img_data, label_data):\n",
    "        # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n",
    "        X, Y = get_anchor_gt([(img, annotation)])\n",
    "\n",
    "        loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "        P_rpn = model_rpn.predict_on_batch(X)\n",
    "        # R: bboxes (shape=(300,4))\n",
    "        # Convert rpn layer to roi bboxes\n",
    "        R = rpn_to_roi(P_rpn[0], P_rpn[1], use_regr=True, overlap_thresh=0.9, max_boxes=300)\n",
    "        X2, Y1, Y2, IouS = calc_iou(R, annotation, classes_count=38)\n",
    "\n",
    "        # If X2 is None means there are no matching bboxes\n",
    "        if X2 is None:\n",
    "            rpn_accuracy_for_epoch.append(0)\n",
    "            continue\n",
    "\n",
    "        # Find out the positive anchors and negative anchors\n",
    "        neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "        pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "\n",
    "        if len(neg_samples) > 0:\n",
    "            neg_samples = neg_samples[0]\n",
    "        else:\n",
    "            neg_samples = []\n",
    "\n",
    "        if len(pos_samples) > 0:\n",
    "            pos_samples = pos_samples[0]\n",
    "        else:\n",
    "            pos_samples = []\n",
    "\n",
    "        rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "\n",
    "        if num_rois > 1:\n",
    "            # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n",
    "            if len(pos_samples) < num_rois // 2:\n",
    "                selected_pos_samples = pos_samples.tolist()\n",
    "            else:\n",
    "                selected_pos_samples = np.random.choice(pos_samples, num_rois // 2, replace=False).tolist()\n",
    "\n",
    "            # Randomly choose (num_rois - num_pos) neg samples\n",
    "            try:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, num_rois - len(selected_pos_samples),\n",
    "                                                        replace=False).tolist()\n",
    "            except:\n",
    "                selected_neg_samples = np.random.choice(neg_samples, num_rois - len(selected_pos_samples),\n",
    "                                                        replace=True).tolist()\n",
    "\n",
    "            # Save all the pos and neg samples in sel_samples\n",
    "            sel_samples = selected_pos_samples + selected_neg_samples\n",
    "        else:\n",
    "            # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "            selected_pos_samples = pos_samples.tolist()\n",
    "            selected_neg_samples = neg_samples.tolist()\n",
    "            if np.random.randint(0, 2):\n",
    "                sel_samples = random.choice(neg_samples)\n",
    "            else:\n",
    "                sel_samples = random.choice(pos_samples)\n",
    "\n",
    "        loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]],\n",
    "                                                     [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "\n",
    "        losses[iter_num, 0] = loss_rpn[1]\n",
    "        losses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "        losses[iter_num, 2] = loss_class[1]\n",
    "        losses[iter_num, 3] = loss_class[2]\n",
    "        losses[iter_num, 4] = loss_class[3]\n",
    "\n",
    "    iter_num += 1\n",
    "    print(\"Iter_num: {}\".format(iter_num))\n",
    "\n",
    "    if iter_num == epoch_length:\n",
    "        loss_rpn_cls = np.mean(losses[:, 0])\n",
    "        loss_rpn_regr = np.mean(losses[:, 1])\n",
    "        loss_class_cls = np.mean(losses[:, 2])\n",
    "        loss_class_regr = np.mean(losses[:, 3])\n",
    "        class_acc = np.mean(losses[:, 4])\n",
    "\n",
    "        mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "        rpn_accuracy_for_epoch = []\n",
    "\n",
    "        curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "        iter_num = 0\n",
    "\n",
    "        if curr_loss < best_loss:\n",
    "            print('Total loss decreased from {} to {}, saving weights'.format(best_loss, curr_loss))\n",
    "            best_loss = curr_loss\n",
    "            model_all.save_weights(output_model_name)\n",
    "\n",
    "        break\n",
    "print('Training complete, exiting.')\n",
    "exit(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}